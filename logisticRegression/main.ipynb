{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainPct = 0.8\n",
       "testPct = 0.19999999999999996\n",
       "dataLoc = /home/ubuntu/data/moons/\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/ubuntu/data/moons/"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainPct = 0.8\n",
    "val testPct = 1 - trainPct\n",
    "val dataLoc = \"/home/ubuntu/data/moons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|summary|               class|                   X|                   Y|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|  count|                5000|                5000|                5000|\n",
      "|   mean|                 0.5|  0.4920739283996744| 0.24980917811368442|\n",
      "| stddev|  0.5000500075012502|  0.9182629238525909|  0.5789451721138708|\n",
      "|    min|0.000000000000000...|-1.00117901148862...|-1.00139457799930...|\n",
      "|    max|1.000000000000000...|9.987326376696318...|9.983360574266741...|\n",
      "+-------+--------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [class: string, X: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[class: string, X: string ... 1 more field]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", \"true\").csv(dataLoc+\"*.csv\")\n",
    "df.describe().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|             class|                 x|                 y|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              5000|              5000|              5000|\n",
      "|   mean|               0.5|    0.492073928418|    0.249809178078|\n",
      "| stddev|0.5000500075012502|0.9182629238273076|0.5789451721684695|\n",
      "|    min|                 0|       -1.96032021|       -1.31754580|\n",
      "|    max|                 1|        2.87904526|        1.90263060|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "precision = 10\n",
       "scale = 8\n",
       "df2 = [class: int, x: decimal(10,8) ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[class: int, x: decimal(10,8) ... 1 more field]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Cast the string fields to numerics\n",
    "import org.apache.spark.sql.types.DecimalType\n",
    "import org.apache.spark.sql.types.IntegerType\n",
    "\n",
    "val precision = 10\n",
    "val scale = 8\n",
    "val df2 = df.withColumn(\"class\", df(\"class\").cast(\"float\").cast(IntegerType))\n",
    ".withColumn(\"x\", df(\"X\").cast(DecimalType(precision, scale)))\n",
    ".withColumn(\"y\", df(\"Y\").cast(DecimalType(precision, scale)))\n",
    "\n",
    "df2.describe().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------+--------------------+\n",
      "|class|          x|          y|            features|\n",
      "+-----+-----------+-----------+--------------------+\n",
      "|    1| 1.08787248|-0.20521282|[1.08787248,-0.20...|\n",
      "|    0|-0.79452014| 0.94437628|[-0.79452014,0.94...|\n",
      "|    1| 0.25275002|-0.55257111|[0.25275002,-0.55...|\n",
      "|    1| 1.88303838| 0.20460338|[1.88303838,0.204...|\n",
      "|    0|-0.55615115| 1.38986852|[-0.55615115,1.38...|\n",
      "|    1| 0.03783374| 0.59497768|[0.03783374,0.594...|\n",
      "|    0|-0.92325788|-0.09656239|[-0.92325788,-0.0...|\n",
      "|    0|-0.49051364| 1.36998264|[-0.49051364,1.36...|\n",
      "|    1|-0.11272890|-0.49344063|[-0.1127289,-0.49...|\n",
      "|    1| 2.47830680| 0.63353222|[2.4783068,0.6335...|\n",
      "|    1| 1.98872986| 0.09737975|[1.98872986,0.097...|\n",
      "|    0| 0.38236654| 0.84140897|[0.38236654,0.841...|\n",
      "|    0|-0.97561951| 1.16236005|[-0.97561951,1.16...|\n",
      "|    0| 0.10791343| 1.09045331|[0.10791343,1.090...|\n",
      "|    1| 1.03539022|-0.00827754|[1.03539022,-0.00...|\n",
      "|    1| 0.91384781|-0.64081650|[0.91384781,-0.64...|\n",
      "|    1|-0.31640354| 0.10729076|[-0.31640354,0.10...|\n",
      "|    1| 1.88428138|-0.06019842|[1.88428138,-0.06...|\n",
      "|    1| 1.49120199|-0.19575386|[1.49120199,-0.19...|\n",
      "|    0|-0.87778762| 1.18658782|[-0.87778762,1.18...|\n",
      "+-----+-----------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "assembler = vecAssembler_217ad54248b2\n",
       "transformed = [class: int, x: decimal(10,8) ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[class: int, x: decimal(10,8) ... 2 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a \"features\" vector for X and Y\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(Array(\"x\", \"y\"))\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val transformed = assembler.transform(df2)\n",
    "\n",
    "transformed.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file has 4023 records\n",
      "Test file has 977 records"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train = [class: int, x: decimal(10,8) ... 2 more fields]\n",
       "test = [class: int, x: decimal(10,8) ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[class: int, x: decimal(10,8) ... 2 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create Train and Test sets\n",
    "val Array(train, test) = transformed.randomSplit(Array(trainPct, testPct))\n",
    "\n",
    "println(\"Train file has \" + train.count + \" records\")\n",
    "print(\"Test file has \" + test.count + \" records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X coefficient: 0.005169208020223935\n",
      "Y coefficient: -0.49186555092064665\n",
      "Intercept: 0.10815666795012131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lr = logreg_e0f52836e834\n",
       "lrModel = logreg_e0f52836e834\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_e0f52836e834"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Build and Fit the model against \"train\" data\n",
    "val lr = new LogisticRegression()\n",
    "  .setMaxIter(10)\n",
    "  .setRegParam(0.3)\n",
    "  .setElasticNetParam(0.8)\n",
    "  .setLabelCol(\"class\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "val lrModel = lr.fit(train)\n",
    "\n",
    "println(\"X coefficient: \"+ lrModel.coefficientMatrix.apply(0,0))\n",
    "println(\"Y coefficient: \"+ lrModel.coefficientMatrix.apply(0,1))\n",
    "\n",
    "println(\"Intercept: \" + lrModel.interceptVector(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions = [class: int, x: decimal(10,8) ... 5 more fields]\n",
       "preds = [x: decimal(10,8), y: decimal(10,8) ... 1 more field]\n",
       "actuals = [x: decimal(10,8), y: decimal(10,8) ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[x: decimal(10,8), y: decimal(10,8) ... 1 more field]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = lrModel.transform(test)\n",
    "val preds = predictions.select(\"x\", \"y\",\"prediction\")\n",
    "preds.coalesce(1).write.option(\"header\", \"true\").csv(dataLoc+\"preds\")\n",
    "val actuals = test.select(\"x\", \"y\", \"class\")\n",
    "actuals.coalesce(1).write.option(\"header\", \"true\").csv(dataLoc+\"actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
