{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOC = /home/tbrownex/data/Hackett/archive/Mastercard/\n",
       "FILE = Egypt.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Egypt.csv"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LOC = \"/home/tbrownex/data/Hackett/archive/Mastercard/\"\n",
    "val FILE = \"Egypt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [_c0: string, _c1: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: string, _c1: string ... 4 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\")\n",
    "         .option(\"header\", \"false\")   // Keep the headers: \"true\" skips them\n",
    "         .option(\"mode\", \"DROPMALFORMED\")\n",
    "         .load(LOC+FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------------+------------+--------------------+----------+--------------------+\n",
      "|summary|  _c0|                 _c1|         _c2|                 _c3|       _c4|                 _c5|\n",
      "+-------+-----+--------------------+------------+--------------------+----------+--------------------+\n",
      "|  count|45901|               45901|       45901|               45901|     45901|               45901|\n",
      "|   mean| null|                null|        null|                null|      null|   5308318.084986665|\n",
      "| stddev| null|                null|        null|                null|      null|  2.21777945948177E7|\n",
      "|    min|Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-01-01|-0.00000000069849...|\n",
      "|    max|Egypt|Small Business Pr...|GG0000008024|Processed-Issuing...|2018-05-01|        9999.9780935|\n",
      "+-------+-----+--------------------+------------+--------------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 45,901 rows and 6 columns:\n",
      " _c0\n",
      " _c1\n",
      " _c2\n",
      " _c3\n",
      " _c4\n",
      " _c5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "formatter = java.text.DecimalFormat@674dc\n",
       "colList = Array(_c0, _c1, _c2, _c3, _c4, _c5)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(_c0, _c1, _c2, _c3, _c4, _c5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val formatter = java.text.NumberFormat.getIntegerInstance\n",
    "print(\"Data has \" +  formatter.format(df.count())+\" rows and \" + formatter.format(df.columns.length)+\" columns:\\n\")\n",
    "\n",
    "// print Column names\n",
    "val colList = df.columns\n",
    "\n",
    "for( a <- colList){\n",
    " println( \" \" + a )\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+--------------------+----------+----------------+\n",
      "|  _c0|                 _c1|         _c2|                 _c3|       _c4|             _c5|\n",
      "+-----+--------------------+------------+--------------------+----------+----------------+\n",
      "|Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-01-01|284533.954567226|\n",
      "|Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-02-01|263907.051428571|\n",
      "|Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-03-01|351187.960412742|\n",
      "|Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-04-01|308846.532766667|\n",
      "|Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-05-01| 258098.75879821|\n",
      "+-----+--------------------+------------+--------------------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)      // equivalent to \"head\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-01-01,284533.954567226]"
     ]
    }
   ],
   "source": [
    "print(df.first())      // Get the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-01-01,284533.954567226]\n",
      "[Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-02-01,263907.051428571]\n",
      "[Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-03-01,351187.960412742]\n",
      "[Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-04-01,308846.532766667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "first4 = Array([Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-01-01,284533.954567226], [Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-02-01,263907.051428571], [Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-03-01,351187.960412742], [Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-04-01,308846.532766667])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array([Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-01-01,284533.954567226], [Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-02-01,263907.051428571], [Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-03-01,351187.960412742], [Egypt,All Cirrus Issuing Programs,GG0000000044,Processed-Acquiring Domestic Cash Volume,2015-04-01,308846.532766667])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Iterate over some rows\n",
    "val first4 = df.take(4)\n",
    "for (x <- first4) {\n",
    "    println(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newNames = List(country, product, account, type, month, amount)\n",
       "df2 = [country: string, product: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[country: string, product: string ... 4 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// rename ALL columns\n",
    "val newNames = Seq(\"country\", \"product\", \"account\",\"type\", \"month\", \"amount\")\n",
    "val df2 = df.toDF(newNames: _*)\n",
    "df2.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- customer: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df3 = [country: string, product: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[country: string, product: string ... 4 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// rename a SINGLE column\n",
    "val df3 = df2.withColumnRenamed(\"account\", \"customer\")\n",
    "df3.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newDF = [country: string, product: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[country: string, product: string ... 5 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Add a column\n",
    "import org.apache.spark.sql.functions.lit    // needed if you're adding the same value for each row\n",
    "val newDF = df3.withColumn(\"new\", lit(10))    // adding value 10 to all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------+--------------------+----------+----------------+---+\n",
      "|country|             product|    customer|                type|     month|          amount|new|\n",
      "+-------+--------------------+------------+--------------------+----------+----------------+---+\n",
      "|  Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-01-01|284533.954567226| 10|\n",
      "|  Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-02-01|263907.051428571| 10|\n",
      "|  Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-03-01|351187.960412742| 10|\n",
      "|  Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-04-01|308846.532766667| 10|\n",
      "|  Egypt|All Cirrus Issuin...|GG0000000044|Processed-Acquiri...|2015-05-01| 258098.75879821| 10|\n",
      "+-------+--------------------+------------+--------------------+----------+----------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 23,877 rows. 22,024 remaining\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "before = 45901\n",
       "filtered = [country: string, product: string ... 5 more fields]\n",
       "after = 22024\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Filter a numeric\n",
    "val before = newDF.count()\n",
    "val filtered = newDF.filter($\"amount\" > 500000.0)      // Filter on a column\n",
    "val after = filtered.count()\n",
    "\n",
    "println(\"Removed \" + formatter.format( before-after) + \" rows. \" + formatter.format(after) +\" remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 rows. 45,901 remaining\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "before = 45901\n",
       "filtered = [country: string, product: string ... 5 more fields]\n",
       "after = 45901\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "45901"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Filter an alpha\n",
    "val before = newDF.count()\n",
    "val filtered = newDF.filter($\"country\" === \"Egypt\")\n",
    "val after = filtered.count()\n",
    "\n",
    "println(\"Removed \" + formatter.format( before-after) + \" rows. \" + formatter.format(after) +\" remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----+-----+------+\n",
      "|country|product|account|type|month|amount|\n",
      "+-------+-------+-------+----+-----+------+\n",
      "+-------+-------+-------+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// check if a column has Nulls\n",
    "df2.filter(\"amount is null\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "// count the number of nulls\n",
    "println(df2.filter($\"amount\".isNull).count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class MyRow\n",
       "data = List(MyRow(1.1,bat), MyRow(2.2,cat), MyRow(NaN,dog))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(MyRow(1.1,bat), MyRow(2.2,cat), MyRow(NaN,dog))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create data with Null\n",
    "case class MyRow(x: Double, y:String)\n",
    "val data = Seq(MyRow(1.1, \"bat\"),MyRow(2.2, \"cat\"),MyRow(Double.NaN, \"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|typ|\n",
      "+---+---+\n",
      "|1.1|bat|\n",
      "|2.2|cat|\n",
      "|NaN|dog|\n",
      "+---+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [id: double, typ: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: double, typ: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = data.toDF(\"id\", \"typ\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|  id|typ|\n",
      "+----+---+\n",
      "| 1.1|bat|\n",
      "| 2.2|cat|\n",
      "|18.0|dog|\n",
      "+----+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "t = [id: double, typ: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: double, typ: string]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// replaces Null with a static value\n",
    "val t = df.na.fill(18)\n",
    "t.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|typ|\n",
      "+---+---+\n",
      "|1.1|bat|\n",
      "|2.2|cat|\n",
      "+---+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "t = [id: double, typ: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: double, typ: string]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// equivalent to \"dropna\"\n",
    "val t = df.na.drop()\n",
    "t.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col = Array(id)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(id)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val col = Array(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.Imputer\n",
    "\n",
    "val imputer = new Imputer()\n",
    "  .setInputCols(col)\n",
    "  .setOutputCols(col.map(c => s\"${c}_imputed\")\n",
    "  .setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.IllegalArgumentException\n",
       "Message: requirement failed: Column typ must be of type equal to one of the following types: [double, float] but was actually of type string.\n",
       "StackTrace:   at scala.Predef$.require(Predef.scala:224)\n",
       "  at org.apache.spark.ml.util.SchemaUtils$.checkColumnTypes(SchemaUtils.scala:60)\n",
       "  at org.apache.spark.ml.feature.ImputerParams$$anonfun$2.apply(Imputer.scala:76)\n",
       "  at org.apache.spark.ml.feature.ImputerParams$$anonfun$2.apply(Imputer.scala:74)\n",
       "  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n",
       "  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n",
       "  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
       "  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n",
       "  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n",
       "  at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\n",
       "  at org.apache.spark.ml.feature.ImputerParams$class.validateAndTransformSchema(Imputer.scala:74)\n",
       "  at org.apache.spark.ml.feature.Imputer.validateAndTransformSchema(Imputer.scala:96)\n",
       "  at org.apache.spark.ml.feature.Imputer.transformSchema(Imputer.scala:175)\n",
       "  at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n",
       "  at org.apache.spark.ml.feature.Imputer.fit(Imputer.scala:124)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| ID|Customer|Amount|\n",
      "+---+--------+------+\n",
      "|  1|       A|   100|\n",
      "|  2|       B|   200|\n",
      "|  3|       A|   300|\n",
      "|  4|       B|   400|\n",
      "|  1|       A|   100|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LOC = /home/tbrownex/data/\n",
       "FILE = spark.csv\n",
       "df = [ID: int, Customer: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ID: int, Customer: string ... 1 more field]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LOC = \"/home/tbrownex/data/\"\n",
    "val FILE = \"spark.csv\"\n",
    "\n",
    "val df = spark.read.format(\"csv\")\n",
    "         .option(\"header\", \"true\")   // whether to keep the headers\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .option(\"mode\", \"DROPMALFORMED\")\n",
    "         .load(LOC+FILE)\n",
    "\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Customer|count|\n",
      "+--------+-----+\n",
      "|       B|    2|\n",
      "|       A|    3|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// get the number of rows per group\n",
    "df.groupBy(\"Customer\").count().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Customer|count|\n",
      "+--------+-----+\n",
      "|       A|    3|\n",
      "|       B|    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "g = RelationalGroupedDataset: [grouping expressions: [Customer: string], value: [ID: int, Customer: string ... 1 more field], type: GroupBy]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RelationalGroupedDataset: [grouping expressions: [Customer: string], value: [ID: int, Customer: string ... 1 more field], type: GroupBy]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// now descending\n",
    "val g = df.groupBy(\"Customer\")\n",
    "g.count().orderBy($\"count\".desc).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Avg\n",
      "A 167\n",
      "B 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "metric = [Customer: string, avg(Amount): double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Customer: string, avg(Amount): double]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// which customer has the highest Avg?\n",
    "val metric = g.avg(\"Amount\").orderBy(\"avg(Amount)\")\n",
    "\n",
    "println(\"Customer\"+ \" Avg\")\n",
    "metric.collect.foreach( (x =>  println(x(0)+\" \"+formatter.format(x(1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// get a column\n",
    "val col = df.select(\"word\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23676"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reduce {\n",
    "    (x, y) =>\n",
    "    if (x.getAs[Int](\"timestamp\") > y.getAs[Int](\"timestamp\")) x else y\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy($\"amount\".desc).show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
